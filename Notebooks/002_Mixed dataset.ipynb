{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09785799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc85899",
   "metadata": {},
   "source": [
    "## Part 1 - Retain inoviridae and microviridae only\n",
    "Caudovirales is the most abundant phage class across all datasets available on PhagesScope. For this reason, I developed this code to specifically collect the Inoviridae and Microviridae classes present in all datasets downloadable from PhagesDB. The ultimate goal is to create a dataset that contains classes Microviridae, Inoviridae and Caudovirales only, with a reasonable amount of data for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24be7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chane the folder path with the one where yout datasets are retained\n",
    "folder_path = r\"-------- FOLDER WITH ALL DATASETS FROM WHICH COLLECT DATA -------------------\"\n",
    "files = glob(os.path.join(folder_path, \"*.csv\"))\n",
    "\n",
    "categories = ['inoviridae', 'microviridae']\n",
    "data_collected = []\n",
    "\n",
    "for f in files:\n",
    "    data = pd.read_csv(f)\n",
    "    print(f'Working with file {f}')\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        if str(data.loc[i, 'Taxonomy']).strip().lower() in categories:\n",
    "            data_collected.append(data.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f224c447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizza un'anteprima\n",
    "file = pd.DataFrame(data_collected).reset_index()\n",
    "file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45c8a2f",
   "metadata": {},
   "source": [
    "## Part 2 - Merge PhagesDB with other samples\n",
    "Once classes Microviridae and Inoviridae have been collected, It has been decided to merge them with PhageDB dataset. This was a purely personal choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72095d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the file path with the one where PhagesDB is\n",
    "file_path = r\"----------------PHAGEDB_FILE_PATH------------------------\"\n",
    "file_2 = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50ce603",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([file_2, file], ignore_index=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81c341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the file_path with the one where you intend to save your dataset\n",
    "file_path = r'-----------------------------------------------------------'\n",
    "dataset.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d172fdb",
   "metadata": {},
   "source": [
    "## Part 3 - illegal sequences\n",
    "Use this part of code to remove illegal sequences (sequences with illegal character not beloging to the standard amino acid alphabet). This part was performed at the previous stages too, but it may come in handy to have this part of the code here too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04817a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"-------------------MIXED_FILE_PATH------------------------\"\n",
    "file = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3677cd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to identify valid sequences --> no O and U\n",
    "def is_valid_sequence(seq, allowed = \"ACDEFGHIKLMNPQRSTVWY\"):\n",
    "    return re.fullmatch(f\"[{allowed}]+\", seq) is not None\n",
    "\n",
    "def clean_invalid_sequences(input_path, output_path, invalid_output_path):\n",
    "    df = pd.read_csv(input_path)\n",
    "\n",
    "    # Validity mask\n",
    "    valid_mask = df[\"Sequence\"].apply(is_valid_sequence)\n",
    "\n",
    "    # Separation\n",
    "    valid_df = df[valid_mask].reset_index(drop=True)\n",
    "    invalid_df = df[~valid_mask].reset_index(drop=True)\n",
    "\n",
    "    # Saving\n",
    "    valid_df.to_csv(output_path, index=False)\n",
    "    invalid_df.to_csv(invalid_output_path, index=False)\n",
    "\n",
    "    print(f\"✅ Valid sequences: {len(valid_df)} saved in {output_path}\")\n",
    "    print(f\"❌ Invalid sequences: {len(invalid_df)} saved in {invalid_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a40cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_invalid_sequences(\n",
    "    input_path = file_path,\n",
    "    output_path = r'--------------------------------------',\n",
    "    invalid_output_path = r'--------------------------------------'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e615d209",
   "metadata": {},
   "source": [
    "## Part 4 - retain illegal characters only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85af9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_2 = r\"------------------------------\"\n",
    "file_2 = pd.read_csv(file_path_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43920cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove valid characters and retain only the invalid ones\n",
    "def rm_valid_characters(seq):\n",
    "    allowed = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "    return \"\".join([char for char in seq if char not in allowed])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e94db33",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_2[\"Sequence\"] = file_2[\"Sequence\"].apply(rm_valid_characters)\n",
    "file_2.to_csv(r\"-----------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
