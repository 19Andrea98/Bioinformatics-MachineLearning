{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HAG6x7zDbn_l"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - dataset descriptive analysis\n",
    "We remove the missing values from all columns and create plots for a descriptive analysis of the dataset. In particular, we generate histograms to visualize the distribution of classes in the columns of interest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the merged dataset in RAM\n",
    "file_path = r\"/media/ssd/Cleaned_datasets/000_dataset/dataset/000_cleaned_MIXED_dataset.csv\"\n",
    "file = pd.read_csv(file_path, sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dataset shape\n",
    "file.shape, file.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in columns\n",
    "file.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove missing values and define a new dataset\n",
    "dataset = file.dropna(how = 'any')\n",
    "dataset = dataset[dataset['Taxonomy'] != '-'].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often in time, missing value are reportes as \"-\". \n",
    "This can undermine the analysis as isnull() function doesn't count them as missing values.\n",
    "For this reason, we carry out an additional check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional check in the \"Host\" column only\n",
    "undetermined_host = (dataset['Host'] != '-').sum()\n",
    "print(undetermined_host)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - plots\n",
    "This part of the code generates plots for the columns of interest. Columns' names may vary from one dataset to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns of interest from the dataset\n",
    "name = ['Taxonomy', 'Completeness', 'Host', 'Lifestyle']\n",
    "labels = {}\n",
    "\n",
    "# Define a dictionary that contains for each name the unique instances present in the dataset\n",
    "for i in name:\n",
    "    labels[i] = dataset[i].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------\n",
    "# PIE CHART 1: HOST DISTRIBUTION\n",
    "# ----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Choose how many categories to keep\n",
    "top_n = 3\n",
    "\n",
    "# Calculate frequencies for each host in the Host column\n",
    "counts = dataset[\"Host\"].value_counts()\n",
    "\n",
    "# Select first N numerous host\n",
    "top_categories = counts[:top_n]\n",
    "\n",
    "# Calculate the sum of the remaining ones\n",
    "other_count = counts[top_n:].sum()\n",
    "\n",
    "# Create a new Series with the top categories and \"Other\"\n",
    "host_summary = top_categories.copy()\n",
    "host_summary[\"Other\"] = other_count\n",
    "\n",
    "# Plot\n",
    "host_summary.plot(\n",
    "    kind = 'pie',\n",
    "    autopct = '%1.1f%%', \n",
    "    figsize=(6, 6)\n",
    "                   )\n",
    "\n",
    "plt.title(\"Distribution of Host\")\n",
    "plt.ylabel('')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------\n",
    "# PIE CHART 2: COMPLETENESS AND LIFESTYLE\n",
    "# ----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "for column in [k for k in labels.keys() if k not in ['Host', 'Taxonomy']]:\n",
    "    counts = dataset[column].value_counts()\n",
    "    total = counts.sum()\n",
    "    \n",
    "    # Create labels with percentages\n",
    "    labels_with_pct = [\n",
    "        f\"{name} ({count / total:.1%})\" for name, count in zip(counts.index, counts)\n",
    "    ]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    wedges, texts = ax.pie(counts, startangle=90)  # no autopct, percentages will be shown in the legend\n",
    "    ax.legend(wedges, labels_with_pct, title=column, loc=\"center left\", bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------\n",
    "# INSTOGRAM: DISTRIBUTION OF TAXONOMY\n",
    "# ----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "for column in [k for k in labels.keys() if k not in ['Host', 'Lifestyle', 'Completeness']]:\n",
    "    counts = dataset[column].value_counts()\n",
    "    total = counts.sum()\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    bars = plt.bar(counts.index.astype(str), counts.values)\n",
    "\n",
    "    # Add percentages above the bars\n",
    "    for bar, count in zip(bars, counts):\n",
    "        percent = count / total * 100\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(),\n",
    "                 f'{percent:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If bar plot is too messy do to numerous classes try this part of the code to make a better graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------\n",
    "# INSTOGRAM: DISTRIBUTION OF TAXONOMY 2\n",
    "# ----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "for column in [k for k in labels.keys() if k not in ['Host', 'Lifestyle', 'Completeness']]:\n",
    "    counts = dataset[column].value_counts()\n",
    "\n",
    "    # Select the top 8 classes\n",
    "    top_classes = counts.head(8)\n",
    "    others_sum = counts[8:].sum()\n",
    "\n",
    "    # Add the \"Other\" class if necessary\n",
    "    if others_sum > 0:\n",
    "        counts_reduced = top_classes.copy()\n",
    "        counts_reduced['Other'] = others_sum\n",
    "    else:\n",
    "        counts_reduced = top_classes\n",
    "\n",
    "    total = counts_reduced.sum()\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    bars = plt.bar(counts_reduced.index.astype(str), counts_reduced.values)\n",
    "\n",
    "    # Add percentages above the bars\n",
    "    for bar, count in zip(bars, counts_reduced):\n",
    "        percent = count / total * 100\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(),\n",
    "                 f'{percent:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - final dataset\n",
    "Use this part of code to remove Lo-quality and Not-determined sequences (Completeness).\n",
    "Moreover, remove illegal protein sequences before feeding data into the ESM-2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the dataset removing Low-qualited and Not-determined sequences\n",
    "final_dataset = dataset.drop(dataset[dataset['Completeness'].isin(['Low-quality', 'Not-determined'])].index).set_index('Phage_ID')\n",
    "final_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this part of code to remove illegal sequences (sequences with characters not beloging to the standard amino acid alphabet). In case of illegal characters in the protein sequence, ESM-2 model returns error during computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to identify valid sequences \n",
    "def is_valid_sequence(seq, allowed = \"ACDEFGHIKLMNPQRSTVWY\"):\n",
    "    return re.fullmatch(f\"[{allowed}]+\", seq) is not None\n",
    "\n",
    "def clean_invalid_sequences(input_path, output_path, invalid_output_path):\n",
    "    df = pd.read_csv(input_path)\n",
    "\n",
    "    # Validity mask\n",
    "    valid_mask = df[\"Sequence\"].apply(is_valid_sequence)\n",
    "\n",
    "    # Separation\n",
    "    valid_df = df[valid_mask].reset_index(drop=True)\n",
    "    invalid_df = df[~valid_mask].reset_index(drop=True)\n",
    "\n",
    "    # Saving\n",
    "    valid_df.to_csv(output_path, index=False)\n",
    "    invalid_df.to_csv(invalid_output_path, index=False)\n",
    "\n",
    "    print(f\"✅ Valid sequences: {len(valid_df)} saved in {output_path}\")\n",
    "    print(f\"❌ Invalid sequences: {len(invalid_df)} saved in {invalid_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_invalid_sequences(\n",
    "    input_path = file_path,\n",
    "    output_path = r'/home/squarna/Desktop/csssleaned_MIXED_dataset.csv',\n",
    "    invalid_output_path = r'/home/squarna/Desktop/cmerdaaaaaaleaned_MIXED_dataset.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned dataset (no illegal sequences and low-quality/not-determined sequences)\n",
    "final_dataset.to_csv('/home/squarna/Desktop/cleaned_MIXED_dataset.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
