{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HAG6x7zDbn_l"
   },
   "outputs": [],
   "source": [
    "import merger_class as Merger\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import tarfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - decompress files\n",
    ".fasta files can be packaged into a single .tar.gz archive. This part of the code is intended to extract the archive and retrieve the original .fasta files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📁 Path of the .tar.gz archive\n",
    "archive_path = r\"-----------------------------------\"  \n",
    "\n",
    "# 📂 Destination folder where to extract the files\n",
    "extraction_path = r\"-----------------------------------\"  \n",
    "\n",
    "# 🛠️ Create the folder if it does not exist\n",
    "os.makedirs(extraction_path, exist_ok = True)\n",
    "\n",
    "# 🔓 Extract the .fasta files (or all)\n",
    "with tarfile.open(archive_path, \"r:gz\") as tar:\n",
    "    for member in tar.getmembers():\n",
    "        if member.name.endswith(\".fasta\"):  # or remove this if to extract everything\n",
    "            tar.extract(member, path=extraction_path)\n",
    "    print(f\"✅ Extraction completed in: {extraction_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - merge .fasta files and create a unique file\n",
    "After decompression, you may obtain multiple .fasta files. This code merges them into a single file to facilitate downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📁 Path of the folder containing the .fasta files\n",
    "input_folder = Path(r\"--------------------------------------\")\n",
    "\n",
    "# 📤 Path of the unified file to create\n",
    "output_file = Path(r\"--------------------------------------\")\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "    merged_count = 0\n",
    "\n",
    "    for fasta_file in input_folder.glob(\"*.fasta\"):\n",
    "        try:\n",
    "            with open(fasta_file, 'r', encoding='utf-8') as infile:\n",
    "                outfile.writelines(infile.readlines())\n",
    "                merged_count += 1\n",
    "                print(f\"✅ Aggiunto: {fasta_file.name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Errore con {fasta_file.name}: {e}\")\n",
    "\n",
    "print(f\"\\n 📦 Combinati {merged_count} file in: {output_file.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a class that merges each .fasta file with its corresponding metadata and removes duplicate Phage_ID entries.\n",
    "If you want to use this class for different datasets, you might need to change column names.\n",
    "I saved the class in a different python file called Merger and imported it as \"Merger\".\n",
    "The class name is Merger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - use the above class to create a row dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths for the .fasta and .tsv files\n",
    "file_path = r\"-----------------------------------\"\n",
    "meta_path = r\"-----------------------------------\"\n",
    "\n",
    "# Initialize the object\n",
    "merger = Merger.Merger(file_path, meta_path)\n",
    "\n",
    "# Create the DataFrames\n",
    "database, meta_file = Merger.Merger(create_database())\n",
    "\n",
    "# This is the final dataset of interest\n",
    "final_data = Merger.Merger(create_final_database(database, meta_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 – Check the output raw dataset\n",
    "\n",
    "Metadata files (.tsv) and sequence files (.fasta) often do not have the same number of entries.  \n",
    "For this reason, it is important to check their lengths:\n",
    "\n",
    "1. **If len(file.fasta) > len(file.tsv)** → the .fasta file contains duplicated Phage_ID/sequences, or the .tsv file is missing some entries.  \n",
    "2. **If len(file.fasta) < len(file.tsv)** → the .tsv file contains duplicated Phage_ID/entries, or it has more entries than the .fasta file.  \n",
    "3. **If len(file.fasta) = len(file.tsv)** → this is a good sign; the files are most likely consistent.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(database))\n",
    "print(len(meta_file))\n",
    "print(len(final_data))\n",
    "final_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5 - save the raw dataset in .csv format\n",
    "Keep in mind that the produced datasets are still **raw**. It means that it can contain protein sequences with illegal characters, missing data and low-determined/not-determined sequences. These are factors to take into account before computing embeddings by ESM-2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define where to save the file\n",
    "csv_output_path = r\"------------------------------------\"\n",
    "\n",
    "# Save the file and print result\n",
    "final_data.to_csv(csv_output_path, index = False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
